{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1821befa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import random\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d313280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"genalaskan2k.csv\")\n",
    "\n",
    "# Group sentences by language\n",
    "language_data = defaultdict(list)\n",
    "for _, row in df.iterrows():\n",
    "    language_data[row[\"Language\"]].append(row[\"Sentence\"])\n",
    "\n",
    "# Ensure each language has exactly 100 sentences\n",
    "for lang, sentences in language_data.items():\n",
    "    assert len(sentences) == 100, f\"Language {lang} has {len(sentences)} sentences, expected 100.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf81144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset based on 3-4-3 setup\n",
    "zero_shot_samples = {lang: sentences[:30] for lang, sentences in language_data.items()}\n",
    "few_shot_samples = {lang: sentences[30:70] for lang, sentences in language_data.items()}  # 40 examples for training\n",
    "validation_samples = {lang: sentences[70:] for lang, sentences in language_data.items()}  # 30 for final test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543c6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client (for API version 1.0.0+)\n",
    "client = openai.OpenAI(api_key=\"insert api key here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5fee23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Use GPT-4o or GPT-4o-mini\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a39fc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-Shot Evaluation\n",
    "zero_shot_results = []\n",
    "for lang, test_sentences in zero_shot_samples.items():\n",
    "    for sentence in test_sentences:\n",
    "        prompt = f\"You are a linguistics expert who knows every single language that exists in this world. What language is this sentence in?\\n\\nSentence: {sentence}. Reply with only the language itself and nothing else.\"\n",
    "        predicted_lang = query_gpt(prompt)\n",
    "        zero_shot_results.append([lang, sentence, predicted_lang])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-Shot Learning with GPT\n",
    "few_shot_results = []\n",
    "for lang, test_sentences in validation_samples.items():\n",
    "    # Format the few-shot prompt\n",
    "    examples = \"\\n\".join(\n",
    "        [f\"Example {i+1}: {sent} (Language: {lang})\" for i, sent in enumerate(few_shot_samples[lang])]\n",
    "    )\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        prompt = f\"\"\"\n",
    "        Here are examples of sentences and their languages:\n",
    "        {examples}\n",
    "        \n",
    "        You are a linguistics expert who knows every single language that exists in this world. Now, what language is this sentence in?\\n\\nSentence: {sentence}. Reply with only the language itself and nothing else.\n",
    "        \"\"\"\n",
    "        predicted_lang = query_gpt(prompt)\n",
    "        few_shot_results.append([lang, sentence, predicted_lang])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be34b023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment complete! Results saved.\n"
     ]
    }
   ],
   "source": [
    "# Convert results to DataFrames and save\n",
    "zero_shot_df = pd.DataFrame(zero_shot_results, columns=[\"True Language\", \"Sentence\", \"Predicted Language\"])\n",
    "few_shot_df = pd.DataFrame(few_shot_results, columns=[\"True Language\", \"Sentence\", \"Predicted Language\"])\n",
    "\n",
    "# Save outputs\n",
    "zero_shot_df.to_csv(\"zero_shot_results2k_mini.csv\", index=False)\n",
    "few_shot_df.to_csv(\"few_shot_results2k_mini.csv\", index=False)\n",
    "\n",
    "print(\"Experiment complete! Results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da1f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
